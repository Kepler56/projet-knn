{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aaf9732",
   "metadata": {},
   "source": [
    "### Import des librairies nécessaires\n",
    "- On importe la librairie <code>math</code> de python pour pouvoir utiliser la méthode <code>sqrt</code> dans notre calcul de la division euclidienne\n",
    "- La librairie random va nous aider à diviser le dataset en deux sets train et test qu'on va voir plus en détails "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39b7841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1082b1",
   "metadata": {},
   "source": [
    "### Charger les données d'un jeu de données\n",
    "- On a définit une fonction <code>load_dataset</code> qui prend en paramètre un fichier de type \"txt\"(par exemple \"data.txt\"). Ensuite on ouvre le fichier pour le lire ligne par ligne avec la méthode <code>readlines()</code> et on créer une liste <code>data_string</code> qui va être constituée des données du fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29187cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    with open(filename) as file:\n",
    "        lines = file.readlines()\n",
    "        data_string = []\n",
    "        for line in lines:\n",
    "            instance_string = line.split(\"\\n\")\n",
    "            \"\"\"Comme on sépare les données avec le caractère de retour à la ligne \"\\n\", une liste vide [''] est créée, \n",
    "            on la supprime donc avec la méthode remove(element)\"\"\"\n",
    "            instance_string.remove('')\n",
    "            for value_string in instance_string:\n",
    "                data_string.append(value_string.split(\";\"))\n",
    "    return data_string\n",
    "        \n",
    "data_string = load_dataset(\"data.txt\")\n",
    "#data_string_pre_test = load_dataset(\"preTest.txt\")\n",
    "data_string_final_test = load_dataset(\"finalTest.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390a640",
   "metadata": {},
   "source": [
    "### Convertir les données qui sont de type string en type float\n",
    "- Après avoir charger le jeu de données dans une liste <code>data_string</code>, nous allons convertir les données de type string en données de type float avec la méthode <code>convert_string_float</code> qui prend en paramètre <code>data_string</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a86f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_float(data_string):\n",
    "    data_float = []\n",
    "    for value in data_string:\n",
    "        instance_float = []\n",
    "        \"\"\"On n'itère pas jusqu'à la fin de la liste car on veut consérver la dernière valeur(la classe) \n",
    "        en string pour la suite du projet\"\"\"\n",
    "        for i in range(len(value)-1):\n",
    "            instance_float.append(float(value[i]))\n",
    "        \"\"\"On ajoute ici la dernière valeur en conservant son type(string)\"\"\"\n",
    "        instance_float.append(value[len(value)-1])\n",
    "        data_float.append(instance_float)\n",
    "    return data_float\n",
    "\n",
    "\"\"\"Pour le jeu de données finalTest.txt on a pas la dernière colonne(la classe) alors on définit une nouvelle méthode\n",
    "qui le prend en compte\"\"\"\n",
    "def convert_string_float_final(data_string):\n",
    "    data_float = []\n",
    "    for value in data_string:\n",
    "        instance_float = []\n",
    "        for i in range(len(value)):\n",
    "            instance_float.append(float(value[i]))\n",
    "        data_float.append(instance_float)\n",
    "    return data_float\n",
    "\n",
    "data_float = convert_string_float(data_string)\n",
    "#data_float_pre_test = convert_string_float(data_string_pre_test)\n",
    "data_float_final_test = convert_string_float_final(data_string_final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e470eb2f",
   "metadata": {},
   "source": [
    "###  Couper en deux ensembles train/test afin d’entraîner notre modèle\n",
    "- La division de notre ensemble de données est essentiel pour une évaluation des performances de prédiction. Dans la plupart des cas, dans notre cas nous allons diviser aléatoirement notre jeu de données en deux sous-ensembles: <code>train_set</code> et <code>test_set</code>.\n",
    "- Pour le faire nous allons utiliser la méthode <code>train_test_set</code> qui prend en paramètre notre liste <code>data_float</code>, <code>split</code>(définie la taille du train_set et du test_set), <code>train_set</code> et <code>test_set</code> vide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1fb4e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_set(data, split, train_set = [], test_set = []):\n",
    "    for i in range(len(data)):\n",
    "        \"\"\"random.random() prends des valeurs aléatoires entre 0 et 1 pour séparer aléatoirement le jeu de données\"\"\"\n",
    "        if random.random() < split:\n",
    "            train_set.append(data[i])\n",
    "        else:\n",
    "            test_set.append(data[i])\n",
    "            \n",
    "train_set = []\n",
    "test_set = []\n",
    "\"\"\"70 % des données disponibles sont allouées à train_set. Les 30 % de données restantes \n",
    "sont réparties de manière égale dans le test_set.\"\"\"\n",
    "train_test_set(data_float, 0.70, train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10384ce8",
   "metadata": {},
   "source": [
    "### Calculer la distance euclidienne\n",
    "- L’algorithme repose sur la notion de « proximité » entre données. Cette proximité est mesurée à l’aide d’une distance.\n",
    "- Nos données sont organisées dans <code>data_float</code> tel que chaque ligne correspond à un objet, et chaque colonne correspond à une valeur.\n",
    "- La méthode <code>distance_euclidienne</code> calcule la distance entre deux lignes element1 et element2 de la façon suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f73bbdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_euclidienne(element1, element2):\n",
    "    ecarts = [element1[j] - element2[j] for j in range(7)]\n",
    "    #somme des carrés des écarts:\n",
    "    sommeCarresEcarts = sum([ecart**2 for ecart in ecarts])\n",
    "    return sqrt(sommeCarresEcarts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3959d",
   "metadata": {},
   "source": [
    "### Algorithme k-nn\n",
    "- Il est utilisé pour prédire la classe d’un nouvel échantillon en fonction de ses voisins les plus proches dans l’espace de caractéristiques.\n",
    "- Pour le faire nous avons créer une méthode <code>knn</code> qui prend en paramètre un <code>element</code> et un <code>k</code> pour renvoyer la liste des k plus proches éléments correspondants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b66741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(element, k):\n",
    "\n",
    "    # on crée la liste des distances entre element et les données du dataset train_set:\n",
    "    distances = [distance_euclidienne(element, item) for item in data_float]\n",
    "\n",
    "    # on ajoute dans une nouvelle list M des tuples avec les distances euclidiennes de element et un index:\n",
    "    distance_index = [(distances[i], i) for i in range(len(distances))]\n",
    "    \n",
    "    # on trie distance_index suivant les distances, ordre croissant:\n",
    "    distance_index.sort(key= lambda x: x[0])\n",
    "    \n",
    "    # On récupère uniquement les indices des k premiers éléments:\n",
    "    top_k = [distance_index[i][1] for i in range(k)]\n",
    "    \n",
    "    # on renvoie la liste des éléments correspondants:\n",
    "    return [data_float[k] for k in top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48eced9",
   "metadata": {},
   "source": [
    "### La classe la plus fréquente parmis les top k\n",
    "- Ensuite après avoir trouver la liste des k premiers éléments on va retourner la classe la plus fréquente avec l'aide de la méthode <code>class_frequente</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da2bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classe_frequente(element, k):\n",
    "\n",
    "    dico = {'0': 0, '1':0, '2':0, '3':0}\n",
    "    # liste des voisins:\n",
    "    voisins = knn(element, k)\n",
    "    # mise à jour compteurs:\n",
    "    for item in voisins:         \n",
    "        dico[item[-1]] += 1  # element[-1] est  la classe (0 ou 1 ou 2 ou 3)\n",
    "\n",
    "    # on cherche maintenant le maximum des valeurs du dico:\n",
    "    effectifs_classe = [(clef, valeur) for clef, valeur in dico.items()] #liste de tuples: (classe, nbr de fois que classe apparaît)\n",
    "    maxi = max(effectifs_classe, key= lambda x: x[1])\n",
    "    return maxi[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da564ac",
   "metadata": {},
   "source": [
    "### Précision de notre algorithme\n",
    "- Cette méthode est utilisée pour trouver la précision de notre algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d87b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(test_set, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(test_set)):\n",
    "        if test_set[i][-1] is predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(test_set)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ab9ae",
   "metadata": {},
   "source": [
    "### On exécute l'algorithm sur le dataset \"finalTest.txt\"\n",
    "- On utilise le modèle afin de prédire la classe pour chaque exemple du fichier \"finalTest.txt\".Ensuite on créer un fichier de sortie \"Sebastien MUGNIER_Sascha CAUCHON_TDC.txt\".\n",
    "- Ce fichier de sortie contiendra chaque prédiction (une prédiction par ligne :0,1,2 ou 3 suivie d’un retour à la ligne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d369dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':        \n",
    "    k = 1\n",
    "    file_result = open('Sebastien MUGNIER_Sascha CAUCHON_TDC.txt', 'w')\n",
    "    predictions = []\n",
    "    for i in range(len(data_float_final_test)):\n",
    "        nouvelElement = data_float_final_test[i]\n",
    "        voisins = knn(nouvelElement, k)\n",
    "        #predictions.append(classe_frequente(nouvelElement, k))\n",
    "        file_result.write(f\"{classe_frequente(nouvelElement, k)}\\n\")\n",
    "    \n",
    "    #accuracy = get_accuracy(data_float_pre_test, predictions)\n",
    "    #file_result.write(f\"Precision: {accuracy}\")\n",
    "    #print(\"Précision: \", accuracy)\n",
    "    file_result.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
